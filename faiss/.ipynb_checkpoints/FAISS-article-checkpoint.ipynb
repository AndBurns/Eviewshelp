{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c1fffc-9ca7-4b70-b6aa-643faf449517",
   "metadata": {},
   "source": [
    "# FAISS example from pinecone.com\n",
    "\n",
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddd129f1-f37b-41f6-887e-b4b91ec347ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Mar  7 11:07:55 2025\n",
    "https://www.pinecone.io/learn/series/faiss/faiss-tutorial/\n",
    "\n",
    "@author: wb268970\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "#The first dataset is in a slightly different format:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b763811-980e-4711-a0d3-b14f03295b9c",
   "metadata": {},
   "source": [
    "## Read the example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04aa52b5-dba1-472c-80b6-dbabfeb459ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14505"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%    \n",
    "res = requests.get('https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/sick2014/SICK_train.txt')\n",
    "# create dataframe\n",
    "data = pd.read_csv(StringIO(res.text), sep='\\t')\n",
    "data.head()\n",
    "\n",
    "#%%\n",
    "sentences = data['sentence_A'].tolist()\n",
    "sentences[:5]\n",
    "\n",
    "#%%\n",
    "# we take all samples from both sentence A and B\n",
    "sentences = data['sentence_A'].tolist()\n",
    "sentence_b = data['sentence_B'].tolist()\n",
    "sentences.extend(sentence_b)  # merge them\n",
    "len(set(sentences))  # together we have ~4.5K unique sentences\n",
    "\n",
    "#%% Extend the dbase\n",
    "urls = [\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.train.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2013/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/images.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2015/images.test.tsv'\n",
    "]\n",
    "\n",
    "# each of these dataset have the same structure, so we loop through each creating our sentences data\n",
    "for url in urls:\n",
    "    res = requests.get(url)\n",
    "    # extract to dataframe\n",
    "    data = pd.read_csv(StringIO(res.text), sep='\\t', header=None, on_bad_lines='skip')\n",
    "    # add to columns 1 and 2 to sentences list\n",
    "    sentences.extend(data[1].tolist())\n",
    "    sentences.extend(data[2].tolist())\n",
    "    \n",
    "len(set(sentences))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c14ceca-d8a4-49fd-9ab5-023b7f2f661c",
   "metadata": {},
   "source": [
    "## Do the embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be7857f-0c7b-4afb-bbf4-875962519a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14504, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "# remove duplicates and NaN\n",
    "sentences = [word for word in list(set(sentences)) if type(word) is str]\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# initialize sentence transformer model\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "# create sentence embeddings\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa06b979-c14b-474c-b964-4ee54a3b352d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"Embeddings.pkl\", 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(sentence_embeddings, outp, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(numpy.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa6cd7c-bf92-4a9b-8c1c-fbb93898d4e9",
   "metadata": {},
   "source": [
    "## Now we try and do the FAIss stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "039621a2-a806-4e8f-993c-cc4cf86f4e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "d = sentence_embeddings.shape[1]\n",
    "d\n",
    "index=faiss.IndexFlatL2(d)\n",
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e7c579e-0aff-45c8-b139-c399067f1127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.add(sentence_embeddings)\n",
    "index.ntotal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dce6c7-364d-424c-99fd-85ca31354a97",
   "metadata": {},
   "source": [
    "# Our L2 index is created yeah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7a762a4-0789-4458-804c-2e30881f03fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = 4\n",
    "xq = model.encode([\"Someone sprints with a football\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8635b571-955f-42b0-b8f0-6bd9524c5acf",
   "metadata": {},
   "source": [
    "do teh search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43b7866a-32b9-42bc-9c8f-b1f557637afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9062 10750 11182  9223]]\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 17.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bd1d268-9bd5-42d5-8ee3-0c1f0195e7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd813b6a-fc64-4e4f-8e98-4eb11f6639d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9062: A group of football players is running in the field',\n",
       " '10750: A group of people playing football is running in the field',\n",
       " '11182: Two groups of people are playing football',\n",
       " '9223: A person playing football is running past an official carrying a football']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NB the print expression in the tutorial does not work, this does\n",
    "[f'{i}: {sentences[i]}' for i in I[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473c421f-2179-4856-bc43-54a99fb96f87",
   "metadata": {},
   "source": [
    "## Using approximate search methods\n",
    "\n",
    "Above is an exhaustive search if the database, below we pre-organize the dataset so that likes are grouped together and then we first search over the central tendancy of all tegh groups and then within the group (or groups) taht arethe closest match.\n",
    "\n",
    "This gives us an approximation of the results from the exhaustive search\n",
    "\n",
    "Voronoi cell method\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33ca2dc0-f87a-4fa3-abda-8d286f85388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create  50 groups\n",
    "#feed the list from above as a quantizer and then generate the upper level index\n",
    "nlist = 50  # how many cells\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12c82a0d-f17b-4d14-bff3-66635aff516d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This new index needs to be trained (is_trained returns false\n",
    "index.is_trained\n",
    "\n",
    "# we train it on the embeddings (takes a moment)\n",
    "index.train(sentence_embeddings)\n",
    "index.is_trained  # check \n",
    "\n",
    "index.add(sentence_embeddings)\n",
    "index.ntotal  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262fecf-ed76-4c7b-b639-7de736347592",
   "metadata": {},
   "source": [
    "## Now we ask the same query as before, but it runs way faster\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb69f893-167b-4332-b2c8-b77e3a299347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9062 10750 11182  9223]]\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65c24e38-9829-4c95-9b86-afd103f196eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9062: A group of football players is running in the field',\n",
       " '10750: A group of people playing football is running in the field',\n",
       " '11182: Two groups of people are playing football',\n",
       " '9223: A person playing football is running past an official carrying a football']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{i}: {sentences[i]}' for i in I[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fda830-5f50-4512-bce2-6bc4893f5c9a",
   "metadata": {},
   "source": [
    "This search just searched exhaustively the closest cell.  As it happens it generate sthe same result as the echaustive search but it need not.  \n",
    "\n",
    "If we want to increase accuracy we can also search the \"closesT adjacent cells.\n",
    "\n",
    "Below searches the 10 closest adjacent cell (nprobe=10). This will be slower but will catch edges that might be better than th  best answers in the closest cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6375866-5f07-4cd0-b45f-70c4a5a041ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9062 10750 11182  9223]]\n"
     ]
    }
   ],
   "source": [
    "index.nprobe=10\n",
    "\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb2b5c8-08d7-44cf-b2b0-d8a5ee058307",
   "metadata": {},
   "source": [
    "## Vector reconstruction\n",
    "\n",
    "We can't pull the answers out of VECTOR_DB on this search because of tegh two step search.  However we can make a mapping and then reconstruct the vector\n",
    "\n",
    "index.make_direct_map()\n",
    "index.reconstruct(7460)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d55066a-8eca-4233-91d8-ae323ddad9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15472068, -0.5122029 ,  1.3126652 ,  0.6024759 , -0.06100069,\n",
       "       -0.93629616, -0.70237976,  0.73408574,  0.5450875 , -0.27290782,\n",
       "       -0.5584474 ,  0.83948326,  0.54898095,  0.12920375,  1.3358675 ,\n",
       "        0.08322317, -0.93952936, -0.86793655, -0.28046873, -0.20230664,\n",
       "       -1.0648402 ,  0.08017921, -0.59579366, -0.7956636 ,  0.37972102,\n",
       "       -0.8312959 , -0.22539063, -1.3049499 , -1.2862183 ,  0.17064631,\n",
       "       -0.22948855,  0.93691784,  0.65546316, -0.18186367, -0.5413576 ,\n",
       "        0.56543756,  1.4237095 ,  0.0801444 , -0.03141323, -0.6890686 ,\n",
       "        0.92161417, -0.08932924,  0.61229473, -0.8886215 , -0.8715622 ,\n",
       "       -0.42966792, -0.07079749,  0.8167949 , -0.22693019, -1.410869  ,\n",
       "        0.42714944, -0.01733742,  0.0430317 , -0.59035105, -0.7381914 ,\n",
       "        0.31170622, -0.07283385, -0.23089044, -0.13359231,  0.7888765 ,\n",
       "       -0.01654837, -0.52540797,  0.7211192 ,  0.27512184, -0.39492846,\n",
       "        0.64258885,  1.3808063 ,  0.23299615, -0.830509  , -0.8804748 ,\n",
       "        0.728259  , -0.4002554 , -0.20337074,  0.81250316, -0.45760503,\n",
       "       -1.3094913 , -0.44706234,  0.48343703, -0.43540636,  0.9226183 ,\n",
       "        0.23609357,  0.31831858,  0.6612767 ,  0.65304   ,  0.22418927,\n",
       "        0.24559128,  1.0415989 ,  0.4590834 , -1.1236463 ,  0.69540185,\n",
       "        0.3006725 , -0.03882645,  0.22064501, -0.6719373 , -0.06416658,\n",
       "        0.51694214, -0.09051162, -0.7635126 ,  0.0671181 , -0.3174511 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.make_direct_map() \n",
    "index.reconstruct(7460)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0af141e7-54d4-4013-85c8-c215e7e624d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9062 10750 11182  9223]]\n"
     ]
    }
   ],
   "source": [
    "D, I = index.search(xq, k)  # search\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7de5d217-0c86-4380-8ba8-5e44b730b239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9062: A group of football players is running in the field',\n",
       " '10750: A group of people playing football is running in the field',\n",
       " '11182: Two groups of people are playing football',\n",
       " '9223: A person playing football is running past an official carrying a football']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{i}: {sentences[i]}' for i in I[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef394b4-2322-4594-b1a6-313d392bb768",
   "metadata": {},
   "source": [
    "## Quantization\n",
    "\n",
    "Dbase is still very large (it can be searched more efficiently but it still uses a lot of space.\n",
    "\n",
    "Quantization reduces the scale of the search problem and increases the speed of search (at the cost of some accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86796e1f-813b-4f7b-b688-44df8e993913",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 8  # number of centroid IDs in final compressed vectors\n",
    "bits = 8 # number of bits in each centroid\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(d)  # we keep the same L2 distance flat index\n",
    "index = faiss.IndexIVFPQ(quantizer, d, nlist, m, bits) \n",
    "index.is_trained\n",
    "\n",
    "index.train(sentence_embeddings)\n",
    "index.add(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0848c53-5ee8-4b8f-979d-f081979816c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8474  9062 10750   182]]\n"
     ]
    }
   ],
   "source": [
    "index.nprobe = 10  # align to previous IndexIVFFlat nprobe value\n",
    "\n",
    "D, I = index.search(xq, k)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd32aafb-43f2-448c-8387-f85dcaef5629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8474: A group of football players running down the field.',\n",
       " '9062: A group of football players is running in the field',\n",
       " '10750: A group of people playing football is running in the field',\n",
       " '182: position in football played by a team member']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{i}: {sentences[i]}' for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0a010-cb71-4661-ad3d-0af62ae2c9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
